---
Date: 2021-10-22
aliases: []
---

# Metadata

**Title** :: Redis 的一致性

**Author** :: #dPaulLai

**Classification** :: [[Redis]]

**Status** :: #🌱

**Type** :: #Note

**ParentNode** :: [[Redis]]

---
> 序
![[Pasted image 20210907172348.png]]

# 什麼是一致性
一致性就是數據保持一致，在分佈式系統中，可以理解為多個節點中數據的值是一致的。

-   **強一致性**：這種一致性級別是最符合使用者直覺的，它要求系統寫入什麼，讀出來的也會是什麼，使用者體驗好，但實現起來往往對系統的效能影響大
-   **弱一致性**：這種一致性級別約束了系統在寫入成功后，不承諾立即可以讀到寫入的值，也不承諾多久之後數據能夠達到一致，但會盡可能地保證到某個時間級別（比如秒級別）后，數據能夠達到一致狀態
-   **最終一致性**：最終一致性是弱一致性的一個特例，系統會保證在一定時間內，能夠達到一個數據一致的狀態。這裡之所以將最終一致性單獨提出來，是因為它是弱一致性中非常推崇的一種一致性模型，也是業界在大型分佈式系統的數據一致性上比較推崇的模型

## 三個經典的快取模式

快取可以提升效能、緩解數據庫壓力，但是使用快取也會導致數據**不一致性**的問題。一般我們是如何使用快取呢？有三種經典的快取模式：

-   Cache-Aside Pattern
-   Read-Through/Write through
-   Write behind

### Cache-Aside Pattern

Cache-Aside Pattern，即**旁路快取模式**，它的提出是爲了儘可能地解決快取與數據庫的數據不一致問題。

#### Cache-Aside 讀流程

**Cache-Aside Pattern**的讀請求流程如下：
![[Pasted image 20210907172430.png]]

1.  讀的時候，先讀快取，快取命中的話，直接返回數據
2.  快取沒有命中的話，就去讀數據庫，從數據庫取出數據，放入快取后，同時返回響應。

#### Cache-Aside 寫流程

**Cache-Aside Pattern**的寫請求流程如下：

![[Pasted image 20210907172439.png]]

更新的時候，先**更新數據庫，然後再刪除快取**。

### Read-Through/Write-Through（讀寫穿透）

**Read/Write Through**模式中，服務端把快取作為主要數據儲存。應用程式跟數據庫快取互動，都是通過**抽像快取層**完成的。

#### Read-Through

**Read-Through**的簡要流程如下

![[Pasted image 20210907172455.png]]

1.  從快取讀取數據，讀到直接返回
2.  如果讀取不到的話，從數據庫載入，寫入快取后，再返回響應。

這個簡要流程是不是跟**Cache-Aside**很像呢？其實**Read-Through**就是多了一層**Cache-Provider**，流程如下：

![[Pasted image 20210907172502.png]]

Read-Through 實際只是在**Cache-Aside**之上進行了一層封裝，它會讓程式程式碼變得更簡潔，同時也減少數據源上的負載。

#### Write-Through

**Write-Through**模式下，當發生寫請求時，也是由**快取抽像層**完成數據源和快取數據的更新,流程如下： 
![[Pasted image 20210907172516.png]]

### Write behind （非同步快取寫入）

**Write behind**跟**Read-Through/Write-Through**有相似的地方，都是由 `Cache Provider` 來負責快取和數據庫的讀寫。它兩又有個很大的不同：**Read/Write Through**是同步更新快取和數據的，**Write Behind**則是隻更新快取，不直接更新數據庫，通過**批量非同步**的方式來更新數據庫。

![[Pasted image 20210907172545.png]]

這種方式下，快取和數據庫的一致性不強，**對一致性要求高的系統要謹慎使用**。但是它適合頻繁寫的場景，MySQL 的**InnoDB Buffer Pool 機制**就使用到這種模式。

## 操作快取的時候，刪除快取呢，還是更新快取？

一般業務場景，我們使用的就是**Cache-Aside**模式。 有些小夥伴可能會問， **Cache-Aside**在寫入請求的時候，為什麼是**刪除快取而不是更新快取**呢？

![[Pasted image 20210907172554.png]]

我們在操作快取的時候，到底應該刪除快取還是更新快取呢？我們先來看個例子：

![[Pasted image 20210907172559.png]]

1.  執行緒 A 先發起一個寫操作，第一步先更新數據庫
2.  執行緒 B 再發起一個寫操作，第二步更新了數據庫
3.  由於網路等原因，執行緒 B 先更新了快取
4.  執行緒 A 更新快取。

這時候，快取儲存的是 A 的數據（老數據），數據庫儲存的是 B 的數據（新數據），數據**不一致**了，臟數據出現啦。如果是**刪除快取取代更新快取**則不會出現這個臟數據問題。

**更新快取相對於刪除快取**，還有兩點劣勢：

-   如果你寫入的快取值，是經過複雜計算才得到的話。更新快取頻率高的話，就浪費效能啦。
-   在寫數據庫場景多，讀數據場景少的情況下，數據很多時候還沒被讀取到，又被更新了，這也浪費了效能呢(實際上，寫多的場景，用快取也不是很劃算了)

## 雙寫的情況下，先運算元據庫還是先操作快取？

`Cache-Aside` 快取模式中，有些小夥伴還是有疑問，在寫入請求的時候，為什麼是**先運算元據庫呢**？為什麼**不先操作快取**呢？

假設有 A、B 兩個請求，請求 A 做更新操作，請求 B 做查詢讀取操作。![[Pasted image 20210907172606.png]]

1.  執行緒 A 發起一個寫操作，第一步 del cache
2.  此時執行緒 B 發起一個讀操作，cache miss
3.  執行緒 B 繼續讀 DB，讀出來一個老數據
4.  然後執行緒 B 把老數據設定入 cache
5.  執行緒 A 寫入 DB 最新的數據

醬紫就有問題啦，**快取和數據庫的數據不一致了。快取儲存的是老數據，數據庫儲存的是新數據**。因此，`Cache-Aside` 快取模式，選擇了先運算元據庫而不是先操作快取。

### 快取延時雙刪

有些小夥伴可能會說，不一定要先運算元據庫呀，採用**快取延時雙刪**策略就好啦？什麼是延時雙刪呢？

![[Pasted image 20210907172625.png]]

1.  先刪除快取
2.  再更新數據庫
3.  休眠一會（比如 1 秒），再次刪除快取。

這個休眠一會，一般多久呢？都是 1 秒？

> 這個休眠時間 = 讀業務邏輯數據的耗時 + 幾百毫秒。 爲了確保讀請求結束，寫請求可以刪除讀請求可能帶來的快取臟數據。

### 刪除快取重試機制

不管是**延時雙刪**還是**Cache-Aside 的先運算元據庫再刪除快取**，如果第二步的刪除快取失敗呢，刪除失敗會導致臟數據哦 ~

> 刪除失敗就多刪除幾次呀,保證刪除快取成功呀 ~ 所以可以引入**刪除快取重試機制**

![[Pasted image 20210907172643.png]]

1.  寫請求更新數據庫
2.  快取因為某些原因，刪除失敗
3.  把刪除失敗的 key 放到訊息佇列
4.  消費訊息佇列的訊息，獲取要刪除的 key
5.  重試刪除快取操作

### 讀取 biglog 非同步刪除快取

重試刪除快取機制還可以，就是會造成好多業務程式碼入侵。其實，還可以通過**數據庫的 binlog 來非同步淘汰 key**。

![[Pasted image 20210907172649.png]]

以 MySQL 為例 可以使用阿里的 canal 將 binlog 日誌採集發送到 MQ 佇列裡面，然後通過 ACK 機制確認處理這條更新訊息，刪除快取，保證數據快取一致性
