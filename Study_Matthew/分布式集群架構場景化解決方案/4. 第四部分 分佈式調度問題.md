---
date: 2021-12-09
aliases: []
---

# Metadata

**Title** :: MyBatis

**Author** :: #Matthew 

**Classification** :: #Learn #Java #Basic #MyBatis

**Status** :: #🌱

**Type** :: #Note

**Previous** ::[[Study_Matthew/分布式集群架構場景化解決方案/3. 第三部分 分佈式ID解決⽅案]]

**ParentNode** :: [[Study_Matthew/分布式集群架構場景化解決方案/分布式集群架構場景化解決方案]]

---

# 第四部分：分佈式調度問題

調度—>定時任務，分佈式調度—>在分佈式集群環境下定時任務這件事

Elastic-job（噹噹⽹開源的分佈式調度框架）

## 第 1 節 定時任務的場景
定時任務形式：每隔⼀定時間/特定某⼀時刻執⾏

例如：

- 訂單審核、出庫
- 訂單超時⾃動取消、⽀付退款
- 禮券同步、⽣成、發放作業
- 物流信息推送、抓取作業、退換貨處理作業
- 數據積壓監控、⽇志監控、服務可⽤性探測作業
- 定時備份數據
- ⾦融系統每天的定時結算
- 數據歸檔、清理作業
- 報表、離線數據分析作業


## 第 2 節 什麼是分佈式調度
什麼是分佈式任務調度？有兩層含義

1. 運⾏在分佈式集群環境下的調度任務（同⼀個定時任務程序部署多份，只應該有⼀個定時任務在執⾏）
2. 分佈式調度—>定時任務的分佈式—>定時任務的拆分（即為把⼀個⼤的作業任務拆分為多個⼩的作業任務，同時執⾏）

![[Study_Matthew/分布式集群架構場景化解決方案/_annex/Pasted image 20211209142123.png]]

## 第 3 節 定時任務與消息隊列的區別
- 共同點
	- 異步處理
		⽐如註冊、下單事件
	- 應⽤解耦
		不管定時任務作業還是MQ都可以作為兩個應⽤之間的⻮輪實現應⽤解耦，這個⻮輪可以中轉數據，當然單體服務不需要考慮這些，服務拆分的時候往往都會考慮
	- 流量削峰
		雙⼗⼀的時候，任務作業和MQ都可以⽤來扛流量，後端系統根據服務能⼒定時處理訂單或者從MQ抓取訂單抓取到⼀個訂單到來事件的話觸發處理，對於前端⽤戶來說看到的結果是已經下單成功了，下單是不受任何影響的

- 本質不同

定時任務作業是時間驅動，⽽MQ是事件驅動；

時間驅動是不可代替的，⽐如⾦融系統每⽇的利息結算，不是說利息來⼀條（利息到來事件）就算

⼀下，⽽往往是通過定時任務批量計算；

所以，定時任務作業更傾向於批處理，MQ傾向於逐條處理；


## 第 4 節 定時任務的實現⽅式
定時任務的實現⽅式有多種。早期沒有定時任務框架的時候，我們會使⽤JDK中的Timer機制和多線程機制（Runnable+線程休眠）來實現定時或者間隔⼀段時間執⾏某⼀段程序；後來有了定時任務框架，⽐如⼤名鼎鼎的Quartz任務調度框架，使⽤時間表達式（包括：秒、分、時、⽇、週、年）配置某⼀個任務什麼時間去執⾏：

- 任務調度框架Quartz回顧示意(我們課程主要內容不是Quartz)

	- 引⼊jar
		```xml
		<!--任务调度框架quartz-->
		<!-- https://mvnrepository.com/artifact/org.quartz-scheduler/quartz --
		>
		<dependency>
		 <groupId>org.quartz-scheduler</groupId>
		 <artifactId>quartz</artifactId>
		 <version>2.3.2</version>
		</dependency>
		```

	- 定時任務作業主調度程序
	```java
	package quartz;
	import org.quartz.*;
	import org.quartz.impl.StdSchedulerFactory;
	public class QuartzMain {
	 // 创建作业任务调度器（类似于公交调度站）
	 public static Scheduler createScheduler() throws SchedulerException {
	  SchedulerFactory schedulerFactory = new StdSchedulerFactory();
	  Scheduler scheduler = schedulerFactory.getScheduler();
	  return scheduler;
	 }
	 // 创建⼀个作业任务（类似于⼀辆公交⻋）
	 public static JobDetail createJob() {
	  JobBuilder jobBuilder = JobBuilder.newJob(DemoJob.class);
	  jobBuilder.withIdentity("jobName","myJob");
	  JobDetail jobDetail = jobBuilder.build();
	  return jobDetail;
	 }
	 /**
	 * 创建作业任务时间触发器（类似于公交⻋出⻋时间表）
	 * cron表达式由七个位置组成，空格分隔
	 * 1、Seconds（秒） 0~59
	 * 2、Minutes（分） 0~59
	 * 3、Hours（⼩时） 0~23
	 * 4、Day of Month（天）1~31,注意有的⽉份不⾜31天
	 * 5、Month（⽉） 0~11,或者
	JAN,FEB,MAR,APR,MAY,JUN,JUL,AUG,SEP,OCT,NOV,DEC
	 * 6、Day of Week(周) 1~7,1=SUN或者 SUN,MON,TUE,WEB,THU,FRI,SAT
	 * 7、Year（年）1970~2099 可选项
	 *示例：
	 * 0 0 11 * * ? 每天的11点触发执⾏⼀次
	 * 0 30 10 1 * ? 每⽉1号上午10点半触发执⾏⼀次
	 */
	 public static Trigger createTrigger() {
	  // 创建时间触发器，按⽇历调度
	  CronTrigger trigger = TriggerBuilder.newTrigger()
	  .withIdentity("triggerName","myTrigger")
	  .startNow()
	  .withSchedule(CronScheduleBuilder.cronSchedule("0/2 * * * * ?"))
	  .build();
	  // 创建触发器，按简单间隔调度
	  /*SimpleTrigger trigger1 = TriggerBuilder.newTrigger()
	  .withIdentity("triggerName","myTrigger")
	  .startNow()
	  .withSchedule(SimpleScheduleBuilder
	  .simpleSchedule()
	  .withIntervalInSeconds(3)
	  .repeatForever())
	  .build();*/
	  return trigger;
	 }
	 // 定时任务作业主调度程序
	 public static void main(String[] args) throws SchedulerException {
	  // 创建⼀个作业任务调度器（类似于公交调度站）
	  Scheduler scheduler = QuartzMain.createScheduler();
	  // 创建⼀个作业任务（类似于⼀辆公交⻋）
	  JobDetail job = QuartzMain.createJob();
	  // 创建⼀个作业任务时间触发器（类似于公交⻋出⻋时间表）
	  Trigger trigger = QuartzMain.createTrigger();
	  // 使⽤调度器按照时间触发器执⾏这个作业任务
	  scheduler.scheduleJob(job,trigger);
	  scheduler.start();
	 }
	}
	```

	- 定義⼀個job，需實現Job接⼝
	```java
	package quartz;
	import org.quartz.Job;
	import org.quartz.JobExecutionContext;
	import org.quartz.JobExecutionException;
	public class DemoJob implements Job {
	 public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException {
	  System.out.println("我是⼀个定时任务逻辑");
	 }
	}
	```

以上，是回顧⼀下任務調度框架Quartz的⼤致⽤法，那麼在分佈式架構環境中使⽤Quartz已經不能更好的滿⾜我們需求，我們可以使⽤專業的分佈式調度框架，這⾥我們推薦使⽤Elastic-job。


## 第 5 節 分佈式調度框架Elastic-Job
### 5.1 Elastic-Job介紹
Elastic-Job是噹噹⽹開源的⼀個分佈式調度解決⽅案，基於Quartz⼆次開發的，由兩個相互獨⽴的⼦項⽬Elastic-Job-Lite和Elastic-Job-Cloud組成。我們要學習的是 Elastic-Job-Lite，它定位為輕量級⽆中⼼化解決⽅案，使⽤Jar包的形式提供分佈式任務的協調服務，⽽Elastic-Job-Cloud⼦項⽬需要結合Mesos以及Docker在雲環境下使⽤。

Elastic-Job的github地址：https://github.com/elasticjob

**主要功能介紹**

- 分佈式調度協調在分佈式環境中，任務能夠按指定的調度策略執⾏，並且能夠避免同⼀任務多實例重複執⾏

- 豐富的調度策略 基於成熟的定時任務作業框架Quartz cron表達式執⾏定時任務

- 彈性擴容縮容 當集群中增加某⼀個實例，它應當也能夠被選舉並執⾏任務；當集群減少⼀個實例時，它所執⾏的任務能被轉移到別的實例來執⾏。

- 失效轉移 某實例在任務執⾏失敗後，會被轉移到其他實例執⾏

- 錯過執⾏作業重觸發 若因某種原因導致作業錯過執⾏，⾃動記錄錯過執⾏的作業，並在上次作業完成後⾃動觸發。

- ⽀持並⾏調度 ⽀持任務分⽚，任務分⽚是指將⼀個任務分為多個⼩任務項在多個實例同時執⾏。

- 作業分⽚⼀致性 當任務被分⽚後，保證同⼀分⽚在分佈式環境中僅⼀個執⾏實例。


### 5.2 Elastic-Job-Lite應⽤

jar包（API） + 安裝zk軟件

Elastic-Job依賴於Zookeeper進⾏分佈式協調，所以需要安裝Zookeeper軟件（3.4.6版本以上），關於Zookeeper，此處我們不做詳解，在階段三會有深度學習，我們此處需要明⽩Zookeeper的本質功能：存儲+通知。

- 安裝Zookeeper（此處單例配置）

	1）我們使⽤3.4.10版本，在linux平台解壓下載的zookeeper-3.4.10.tar.gz

	2）進⼊conf⽬錄，cp zoo_sample.cfg zoo.cfg

	3）進⼊bin⽬錄，啟動zk服務

	啟動 ./zkServer.sh start

	停⽌ ./zkServer.sh stop

	查看狀態 ./zkServer.sh status

	**Zookeeper的樹形節點結構圖**

	![[Study_Matthew/分布式集群架構場景化解決方案/_annex/Pasted image 20211209171336.png]]
	
- 引⼊Jar包
	```xml
	<!-- https://mvnrepository.com/artifact/com.dangdang/elastic-job-lite-core
	-->
	<dependency>
	 <groupId>com.dangdang</groupId>
	 <artifactId>elastic-job-lite-core</artifactId>
	 <version>2.1.5</version>
	</dependency>
	```

- 定時任務實例
	- 需求：每隔兩秒鐘執⾏⼀次定時任務（resume表中未歸檔的數據歸檔到resume_bak表中，每次歸檔1條記錄）
	
	1）resume_bak和resume表結構完全⼀樣
	
	2）resume表中數據歸檔之後不刪除，只將state置為"已歸檔"
	
	- 數據表結構
	```sql
	-- ----------------------------
	-- Table structure for resume
	-- ----------------------------
	DROP TABLE IF EXISTS `resume`;
	CREATE TABLE `resume` (
	 `id` bigint(20) NOT NULL AUTO_INCREMENT,
	 `name` varchar(255) DEFAULT NULL,
	 `sex` varchar(255) DEFAULT NULL,
	 `phone` varchar(255) DEFAULT NULL,
	 `address` varchar(255) DEFAULT NULL,
	 `education` varchar(255) DEFAULT NULL,
	 `state` varchar(255) DEFAULT NULL,
	 PRIMARY KEY (`id`)
	) ENGINE=InnoDB AUTO_INCREMENT=1001 DEFAULT CHARSET=utf8;
	SET FOREIGN_KEY_CHECKS = 1;
	```
	
	- 程序開發
		- 定時任務類
			```java
			package elasticjob;
			import com.dangdang.ddframe.job.api.ShardingContext;
			import com.dangdang.ddframe.job.api.simple.SimpleJob;
			import util.JdbcUtil;
			import java.sql.Connection;
			import java.sql.PreparedStatement;
			import java.sql.ResultSet;
			import java.util.List;
			import java.util.Map;
			public class BackupJob implements SimpleJob {
			 // 定时任务每执⾏⼀次都会执⾏如下的逻辑
			 @Override
			 public void execute(ShardingContext shardingContext) {
			  /*
			  从resume数据表查找1条未归档的数据，将其归档到resume_bak表，并更新状态为已归档（不删除原数据）
			  */
			  // 查询出⼀条数据
			  String selectSql = "select * from resume where	state='未归档' limit 1";
			  List<Map<String, Object>> list = JdbcUtil.executeQuery(selectSql);
			  if(list == null || list.size() == 0) {
			   return;
			  }
			  Map<String, Object> stringObjectMap = list.get(0);
			  long id = (long) stringObjectMap.get("id");
			  String name = (String) stringObjectMap.get("name");
			  String education = (String) stringObjectMap.get("education");
			  // 打印出这条记录
			  System.out.println("======>>>id：" + id + " name：" + name + " education：" + education);
			  // 更改状态
			  String updateSql = "update resume set state='已归档' where id=?";
			  JdbcUtil.executeUpdate(updateSql,id);
			  // 归档这条记录
			  String insertSql = "insert into resume_bak select * from resume where id=?";
			  JdbcUtil.executeUpdate(insertSql,id);
			 }
			}
			```

		- 主類
			```java
			package elasticjob;
			import com.dangdang.ddframe.job.config.JobCoreConfiguration;
			import com.dangdang.ddframe.job.config.simple.SimpleJobConfiguration;
			import com.dangdang.ddframe.job.lite.api.JobScheduler;
			import com.dangdang.ddframe.job.lite.config.LiteJobConfiguration;
			import com.dangdang.ddframe.job.reg.base.CoordinatorRegistryCenter;
			import com.dangdang.ddframe.job.reg.zookeeper.ZookeeperConfiguration;
			import com.dangdang.ddframe.job.reg.zookeeper.ZookeeperRegistryCenter;
			public class ElasticJobMain {
			 public static void main(String[] args) {
			  // 配置注册中⼼zookeeper，zookeeper协调调度，不能让任务重复执⾏，通过命名空间分类管理任务，对应到zookeeper的⽬录
			  ZookeeperConfiguration zookeeperConfiguration = new ZookeeperConfiguration("localhost:2181","data-archive-job");
			  CoordinatorRegistryCenter coordinatorRegistryCenter = new ZookeeperRegistryCenter(zookeeperConfiguration);
			  coordinatorRegistryCenter.init();
			  // 配置任务
			  JobCoreConfiguration jobCoreConfiguration = JobCoreConfiguration.newBuilder("archive-job","*/2 * * * * ?",1).build();
			  SimpleJobConfiguration simpleJobConfiguration = new SimpleJobConfiguration(jobCoreConfiguration,BackupJob.class.getName());
			  // 启动任务
			  new JobScheduler(coordinatorRegistryCenter,LiteJobConfiguration.newBuilder(simpleJobConfiguration).build()).init();
			 }
			}
			```

		- JdbcUtil⼯具類
			```java
			package util;
			import java.sql.*;
			import java.util.ArrayList;
			import java.util.HashMap;
			import java.util.List;
			import java.util.Map;
			public class JdbcUtil {
			 //url
			 private static String url = "jdbc:mysql://localhost:3306/job?characterEncoding=utf8&useSSL=false";
			 //user
			 private static String user = "root";
			 //password
			 private static String password = "123456";
			 //驱动程序类
			 private static String driver = "com.mysql.jdbc.Driver";
			 static {
			  try {
			   Class.forName(driver);
			  } catch (ClassNotFoundException e) {
			   // TODO Auto-generated catch block
			   e.printStackTrace();
			  }
			 }
			 
			 public static Connection getConnection() {
			 
			 try {
			  return DriverManager.getConnection(url, user, password);
			 } catch (SQLException e) {
			  // TODO Auto-generated catch block
			  e.printStackTrace();
			 }
			  return null;
			 }
				
			 public static void close(ResultSet rs, PreparedStatement ps, Connection con) {
			  if (rs != null) {
			   try {
			    rs.close();
			   } catch (SQLException e) {
			    // TODO Auto-generated catch block
			    e.printStackTrace();
			   } finally {
			    if (ps != null) {
			     try {
			      ps.close();
			     } catch (SQLException e) {
			      // TODO Auto-generated catch block
			      e.printStackTrace();
			     } finally {
			      if (con != null) {
			       try {
			        con.close();
			       } catch (SQLException e) {
			        // TODO Auto-generated catch block
			        e.printStackTrace();
			       }
			      }
			     }
			    }
			   }
			  }
			 }

			 public static void executeUpdate(String sql,Object...obj) {
			  Connection con = getConnection();
			  PreparedStatement ps = null;
			  try {
			   ps = con.prepareStatement(sql);
			   for (int i = 0; i < obj.length; i++) {
			    ps.setObject(i + 1, obj[i]);
			   }
			   ps.executeUpdate();
			  } catch (SQLException e) {
			   // TODO Auto-generated catch block
			   e.printStackTrace();
			  } finally {
			   close(null, ps, con);
			  }
			 }

			 public static List<Map<String,Object>> executeQuery(String sql, Object...obj) {
			  Connection con = getConnection();
			  ResultSet rs = null;
			  PreparedStatement ps = null;
			  try {
			   ps = con.prepareStatement(sql);
			   for (int i = 0; i < obj.length; i++) {
			    ps.setObject(i + 1, obj[i]);
			   }
			   rs = ps.executeQuery();

			   List<Map<String, Object>> list = new ArrayList<>();

			   int count = rs.getMetaData().getColumnCount();

			   while (rs.next()) {

			   Map<String, Object> map = new HashMap<String, Object>();
			   for (int i = 0; i < count; i++) {
			    Object ob = rs.getObject(i + 1);
			    String key = rs.getMetaData().getColumnName(i + 1);
			    map.put(key, ob);
			   }
			   list.add(map); 
			  }  
			 return list;
			 } catch (SQLException e) {
			  // TODO Auto-generated catch block
			  e.printStackTrace();
			 } finally {
			  close(rs, ps, con);
			 }
			  return null;
			 }
			}
			```

	- 測試
	
	1）可先啟動⼀個進程，然後再啟動⼀個進程（兩個進程模擬分佈式環境下，通⼀個定時任務部署了兩份在⼯作）

	2）兩個進程逐個啟動，觀察現象

	3）關閉其中執⾏的進程，觀察現象

	- Leader節點選舉機制

	每個Elastic-Job的任務執⾏實例App作為Zookeeper的客戶端來操作ZooKeeper的znode

	（1）多個實例同時創建/leader節點

	（2）/leader節點只能創建⼀個，後創建的會失敗，創建成功的實例會被選為leader節點，執⾏任務


### 5.4 Elastic-Job-Lite輕量級去中⼼化的特點

如何理解輕量級和去中⼼化？

![[Study_Matthew/分布式集群架構場景化解決方案/_annex/Pasted image 20211209173544.png]]


### 5.5 任務分⽚
⼀個⼤的⾮常耗時的作業Job，⽐如：⼀次要處理⼀億的數據，那這⼀億的數據存儲在數據庫中，如果⽤⼀個作業節點處理⼀億數據要很久，在互聯⽹領域是不太能接受的，互聯⽹領域更希望機器的增加去橫向擴展處理能⼒。所以，ElasticJob可以把作業分為多個的task（每⼀個task就是⼀個任務分⽚），每⼀個task交給具體的⼀個機器實例去處理（⼀個機器實例是可以處理多個task的），但是具體每個task執⾏什麼邏輯由我們⾃⼰來指定。

![[Study_Matthew/分布式集群架構場景化解決方案/_annex/Pasted image 20211209173622.png]]

Strategy策略定義這些分⽚項怎麼去分配到各個機器上去，默認是平均去分，可以定制，⽐如某⼀個機器負載 ⽐較⾼或者預配置⽐較⾼，那麼就可以寫策略。分⽚和作業本身是通過⼀個註冊中⼼協調的，因為在分佈式環境下，狀態數據肯定集中到⼀點，才可以在分佈式中溝通。

**分⽚代碼**

![[Study_Matthew/分布式集群架構場景化解決方案/_annex/Pasted image 20211209173708.png]]

![[Study_Matthew/分布式集群架構場景化解決方案/_annex/Pasted image 20211209173722.png]]


### 5.6 彈性擴容

![[Study_Matthew/分布式集群架構場景化解決方案/_annex/Pasted image 20211209173747.png]]

新增加⼀個運⾏實例app3，它會⾃動註冊到註冊中⼼，註冊中⼼發現新的服務上線，註冊中⼼會通知ElasticJob 進⾏重新分⽚，那麼總得分⽚項有多少，那麼就可以搞多少個實例機器，⽐如完全可以分1000⽚

最多就可以有多少app實例，，，，機器能成的主，完全可以分1000⽚

那麼就可以搞1000台機器⼀起執⾏作業

注意：

1）分⽚項也是⼀個JOB配置，修改配置，重新分⽚，在下⼀次定時運⾏之前會重新調⽤分⽚算法，那麼這個分⽚算法的結果就是：哪台機器運⾏哪⼀個⼀⽚，這個結果存儲到zk中的，主節點會把分⽚給分好放到註冊中⼼去，然後執⾏節點從註冊中⼼獲取信息(執⾏節點在定時任務開啟的時候獲取相應的分⽚)。

2）如果所有的節點掛掉值剩下⼀個節點，所有分⽚都會指向剩下的⼀個節點，這也是ElasticJob的⾼可⽤。


